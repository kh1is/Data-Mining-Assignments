{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdO3a8N8j-DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload File\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkCd5aWTmw4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data content\n",
        "f =open(\"/content/wdbc.data\", \"r\")\n",
        "if f.mode == 'r':\n",
        "    dataContents =f.readlines()\n",
        "\n",
        "dataContents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu_7aC67nHuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating list of list of strings for data content\n",
        "splitedContents = [i.split(\",\") for i in dataContents]\n",
        "splitedContents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdIcFEjznL7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating dataFrame\n",
        "import pandas as pd\n",
        "\n",
        "dataFrame = pd.DataFrame(splitedContents)\n",
        "dataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwNanNLKnnof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Histogram plot for class 'M' and class 'B'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#tmp = dataframe for class B only\n",
        "tmp = dataFrame.loc[dataFrame[1] == 'B',:]\n",
        "\n",
        "#tmp2 = dataframe for class M only\n",
        "tmp2 = dataFrame.loc[dataFrame[1] == 'M',:]\n",
        "\n",
        "plt.hist(tmp)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kSHd5lfoPEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Histogram plot for column class only\n",
        "import matplotlib.pyplot as plt\n",
        "# extract column of the classes from dataframe\n",
        "Class = dataFrame.loc[:,1]\n",
        "Class\n",
        "\n",
        "plt.hist(Class)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cldkPrRZpd1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove first and second columns (instance id and class) \n",
        "Data = dataFrame.drop(columns=0)\n",
        "Data = Data.drop(columns=1)\n",
        "Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guE3C5RlplAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create scatter plot for the first attribute\n",
        "import numpy\n",
        "\n",
        "plt.figure(figsize=(52,2))\n",
        "plt.scatter(dataFrame.loc[1:100,2],dataFrame.loc[1:100,1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hg5teErqSPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create attribute list to create box plot\n",
        "attributesList = []\n",
        "i = 2\n",
        "j = 0\n",
        "while i < 32:\n",
        "    listTemp = Data.loc[:,i].values.tolist()\n",
        "    listTemp2 = [float(k) for k in listTemp]\n",
        "    attributesList.insert(j , listTemp2)\n",
        "    i = i + 1\n",
        "    j = j + 1\n",
        "\n",
        "attributesList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHE-P5U2qUYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create boxplot\n",
        "plt.figure(figsize=(20,25))\n",
        "plt.boxplot(attributesList)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nx9M6mfqip8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate correlation coefficient for Attribute List\n",
        "import numpy\n",
        "correlationMatrix = numpy.corrcoef(attributesList)\n",
        "correlationMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amrro-gEq57L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize correlationMatrix using imshow\n",
        "plt.imshow(correlationMatrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04YhI0FUzcA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Zscore normalization\n",
        "from scipy import stats\n",
        "\n",
        "normalizedZscoreList = stats.zscore(attributesList)\n",
        "\n",
        "print(normalizedZscoreList)\n",
        "\n",
        "plt.hist(attributesList[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.hist(normalizedZscoreList[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.boxplot(attributesList[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.boxplot(normalizedZscoreList[0])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dt4bOm84QFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transpose normalizedAtrributeList \n",
        "transposedNormalizedData = pd.DataFrame(normalizedZscoreList)\n",
        "transposedNormalizedData = transposedNormalizedData.transpose()\n",
        "normalizedDataList = transposedNormalizedData.values.tolist()\n",
        "normalizedDataList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isFxR2Uh7QHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select number of components (feature projection)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(normalizedDataList)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])\n",
        "principalDf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joZXXjIu-PpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split data set to training data (70% of data, 398 instances) and test data (30% of data, 171 instances)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=4, test_size=0.3,train_size=0.7, random_state=1)\n",
        "\n",
        "#convert data and Class (dataframes) to arrays\n",
        "dataArray = numpy.array(principalDf)\n",
        "classArray = numpy.array(Class)\n",
        "\n",
        "#sss.get_n_splits(dataArray, classArray)\n",
        "\n",
        "for train_index, test_index in sss.split(dataArray, classArray):\n",
        "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    data_train, data_test = dataArray[train_index], dataArray[test_index]\n",
        "    Class_train, Class_test = classArray[train_index], classArray[test_index]\n",
        "\n",
        "print(\"-----------------------------\")\n",
        "print(len(data_train))\n",
        "print(\"==========\")\n",
        "print(data_train)\n",
        "print(\"-----------------------------\")\n",
        "print(len(data_test))\n",
        "print(\"==========\")\n",
        "print(data_test)\n",
        "print(\"-----------------------------\")\n",
        "print(len(Class_train))\n",
        "print(\"==========\")\n",
        "print(Class_train)\n",
        "print(\"-----------------------------\")\n",
        "print(len(Class_test))\n",
        "print(\"==========\")\n",
        "print(Class_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2qNkTO0_t-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create K-neighbours model\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KN_model = KNeighborsClassifier(n_neighbors=8)\n",
        "# Train the model using the training sets\n",
        "KN_model.fit(data_train,Class_train)\n",
        "#Predict Output\n",
        "KN_predicted= KN_model.predict(data_test) \n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Class_test, KN_predicted))\n",
        "print(metrics.confusion_matrix(Class_test, KN_predicted))\n",
        "print(metrics.classification_report(Class_test, KN_predicted,target_names=['M','B']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrizZ_iPBF4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create SVM model\n",
        "#Import svm model\n",
        "from sklearn import svm\n",
        "#Create a svm Classifier\n",
        "SVM_model = svm.SVC(kernel='linear',C=1) # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "SVM_model.fit(data_train, Class_train)\n",
        "#Predict the response for test dataset\n",
        "SVM_pred = SVM_model.predict(data_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Class_test, SVM_pred))\n",
        "print(metrics.confusion_matrix(Class_test, SVM_pred))\n",
        "print(metrics.classification_report(Class_test, SVM_pred,target_names=['M','B']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8AfbyDiBtZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create SVC model\n",
        "\n",
        "# Create a SVC classifier using an RBF kernel\n",
        "SVC_model = svm.SVC(kernel='rbf', random_state=0, gamma=1, C=10)\n",
        "# Train the classifier\n",
        "SVC_model.fit(data_train, Class_train)# Visualize the decision boundaries\n",
        "#Predict the response for test dataset\n",
        "SVC_pred = SVC_model.predict(data_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Class_test, SVC_pred))\n",
        "print(metrics.confusion_matrix(Class_test, SVC_pred))\n",
        "print(metrics.classification_report(Class_test, SVC_pred,target_names=['M','B']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1CsKNMKDDtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create logistic regression model\n",
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# instantiate the model (using the default parameters)\n",
        "LogReg_model = LogisticRegression(C=10000)\n",
        "# fit the model with data\n",
        "LogReg_model.fit(data_train,Class_train)#\n",
        "LogReg_pred=LogReg_model.predict(data_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Class_test, LogReg_pred))\n",
        "print(metrics.confusion_matrix(Class_test, LogReg_pred))\n",
        "print(metrics.classification_report(Class_test, LogReg_pred,target_names=['M','B']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uqDQlEND6Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply GridSearchCV on each classfifier model to get best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "KN_params = { \n",
        "        'n_neighbors' : [1,2,3,4,5,6,7,8]\n",
        "}\n",
        "\n",
        "SVM_params = { \n",
        "    'C': [1,10,100,1000,10000]\n",
        "}\n",
        "\n",
        "SVC_params = { \n",
        "    'C': [1,10,100,1000,10000],\n",
        "    'gamma' : [0.01,0.1,1,10,100]\n",
        "}\n",
        "\n",
        "LogReg_params = { \n",
        "    'C': [1,10,100,1000,10000]\n",
        "}\n",
        "\n",
        "CV_KN = GridSearchCV(estimator=KN_model, param_grid=KN_params, cv= 10)\n",
        "CV_KN.fit(data_train, Class_train)\n",
        "print(\"KN_best_parameters\",CV_KN.best_params_ )\n",
        "\n",
        "CV_SVM = GridSearchCV(estimator=SVM_model, param_grid=SVM_params, cv= 10)\n",
        "CV_SVM.fit(data_train, Class_train)\n",
        "print(\"SVM_best_parameters\",CV_SVM.best_params_ )\n",
        "\n",
        "CV_SVC = GridSearchCV(estimator=SVC_model, param_grid=SVC_params, cv= 10)\n",
        "CV_SVC.fit(data_train, Class_train)\n",
        "print(\"SVC_best_parameters\",CV_SVC.best_params_ )\n",
        "\n",
        "CV_LogReg = GridSearchCV(estimator=LogReg_model, param_grid=LogReg_params, cv= 10)\n",
        "CV_LogReg.fit(data_train, Class_train)\n",
        "print(\"LogReg_best_parameters\",CV_LogReg.best_params_ )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}